{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e774218-ea45-4d9f-9925-4f66233aa8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/users/zwu/envs/xclip/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, AutoModel\n",
    "from torch import cat, save\n",
    "from numpy import array\n",
    "from math import ceil\n",
    "\n",
    "from decord import VideoReader, cpu\n",
    "from IPython.display import HTML\n",
    "\n",
    "from utils import compute_clip_sim, get_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eaac221-9567-45e9-9171-6645b8ae5663",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd5bfab8-571b-49ca-be1f-990b93c273f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"microsoft/xclip-base-patch16-zero-shot\"\n",
    "processor, model = AutoProcessor.from_pretrained(model_name), AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "998b7cab-1273-4d7c-839a-2c9661cfa491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " videos/aerial.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video controls> <source src=\"videos/aerial.mp4\" type=\"video/mp4\"> </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = input()\n",
    "vr = VideoReader(filename, ctx=cpu(0))\n",
    "HTML(f'<video controls> <source src=\"{filename}\" type=\"video/mp4\"> </video>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dc60578-2a3f-4b22-a411-17c8d5402ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_frame_indices(videoreader, sample_length=16, num_frames_per_sample=32):\n",
    "    '''\n",
    "    sample_length is in seconds\n",
    "    return list of n lists of frame indices, where n is num_samples, AKA num_vectors\n",
    "    '''\n",
    "    range_per_sample = int(sample_length * videoreader.get_avg_fps())  # range in # of frames\n",
    "    interval_per_frame_of_sample = ceil(range_per_sample / num_frames_per_sample)\n",
    "    num_samples = int(len(videoreader) // range_per_sample)\n",
    "    print('draws one frame every', interval_per_frame_of_sample, 'frames over', range_per_sample, 'frames')\n",
    "    \n",
    "    indices = []\n",
    "    for i in range(0, num_samples):\n",
    "        _indices = range(i*range_per_sample, (i+1)*range_per_sample, interval_per_frame_of_sample)\n",
    "        indices.append([*_indices])\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57740354-afdf-4a95-abce-4f019935bf5e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "draws one frame every 12 frames over 383 frames\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "idx = array(get_sample_frame_indices(vr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b18815c-6e9a-4e01-9ec5-fd0bbd427bee",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_features = []\n",
    "for i in range(0, len(idx)):\n",
    "    video_features.append(\n",
    "        model.get_video_features(**processor(\n",
    "            videos=list(vr.get_batch(idx[i]).asnumpy()), return_tensors=\"pt\"\n",
    "        ))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "914a78e3-f02d-4666-96a2-32dbdb337a17",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 512])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_features = cat(video_features); video_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1217856-849c-40f0-8beb-880019014494",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(video_features, 'feature_vectors/aerial_17samples.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc755db2-bef1-4da7-9d99-5526a311ff81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content found at frame #: tensor(3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.1914, 0.1939, 0.1907, 0.2066, 0.2008, 0.1922, 0.1787, 0.1922, 0.1860,\n",
       "         0.1821, 0.1869, 0.1558, 0.1713, 0.1732, 0.1821, 0.1817, 0.1773]),\n",
       " None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features = model.get_text_features(**processor(text=[\"moving cars\"], return_tensors=\"pt\", padding=True))\n",
    "logits = compute_clip_sim(video_features, text_features)\n",
    "*logits, print('Content found at frame #:', logits.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9261415-2573-43bb-af13-0b5222b999cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content found at frame #: tensor(3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.1914, 0.1939, 0.1907, 0.2066, 0.2008, 0.1922, 0.1787, 0.1922, 0.1860,\n",
       "         0.1821, 0.1869, 0.1558, 0.1713, 0.1732, 0.1821, 0.1817, 0.1773]),\n",
       " None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features = model.get_text_features(**processor(text=[\"moving cars\"], return_tensors=\"pt\", padding=True))\n",
    "logits = compute_clip_sim(video_features, text_features)\n",
    "*logits, print('Content found at frame #:', logits.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1d5a26b-d3f5-43fc-86c7-24c1dd3378df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content found at frame #: tensor(15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.1890, 0.1825, 0.1760, 0.1883, 0.1835, 0.1720, 0.1705, 0.1795, 0.1687,\n",
       "         0.1727, 0.1925, 0.1745, 0.1795, 0.1749, 0.1955, 0.2008, 0.1892]),\n",
       " None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features = model.get_text_features(**processor(text=[\"docked ship\"], return_tensors=\"pt\", padding=True))\n",
    "logits = compute_clip_sim(video_features, text_features)\n",
    "*logits, print('Content found at frame #:', logits.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc9edc1c-373a-4ee7-9600-919c2545ba3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content found at frame #: tensor(1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.2215, 0.2297, 0.2120, 0.2111, 0.2208, 0.2209, 0.2128, 0.2156, 0.2126,\n",
       "         0.2190, 0.2190, 0.1724, 0.2097, 0.2243, 0.2260, 0.2063, 0.2031]),\n",
       " None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features = model.get_text_features(**processor(text=[\"tower\"], return_tensors=\"pt\", padding=True))\n",
    "logits = compute_clip_sim(video_features, text_features)\n",
    "*logits, print('Content found at frame #:', logits.argmax())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xclip",
   "language": "python",
   "name": "xclip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
